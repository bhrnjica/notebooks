{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Installing package Microsoft.ML................done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package Microsoft.ML, version 1.4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installing package Daany.DataFrame.....done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package Daany.DataFrame, version 0.6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installing package Daany.DataFrame.Ext.....done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package Daany.DataFrame.Ext, version 0.6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installing package Daany.Stat......done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package Daany.Stat, version 0.6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installing package XPlot.Plotly....done!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully added reference to package XPlot.Plotly, version 3.0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.ML\"\n",
    "    \n",
    "//Install Daany packages\n",
    "#r \"nuget:Daany.DataFrame\"\n",
    "#r \"nuget:Daany.DataFrame.Ext\"\n",
    "#r \"nuget:Daany.Stat\"\n",
    "    \n",
    "//Install XPlot package\n",
    "#r \"nuget:XPlot.Plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance on .NET Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This article is based on the Azure AI Gallery article: [Predictive Maintenance Modelling Guide]( https://gallery.azure.ai/Collection/Predictive-Maintenance-Modelling-Guide-1). The datasets used in the article can also be found at Azure AI Gallery. \n",
    "\n",
    "However, this notebook is completely implemented on .NET platform using `C# Jupyter Notebook` and `Daany` - C# data analytics library. There are small differences between this notebook and the notebooks at the official azure gallery portal, but in most cases, the code follows the steps defined there. \n",
    "The purpose of this notebook is to demonstrate how to use `.NET Jupyter Notebook` with `Daany.DataFrame` and `ML.NET` in order to prepare the data and build the Predictive Maintenance Model on .NET platform.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Introduction to Predictive Maintenance\n",
    "\n",
    "Simply speaking it is a technique to determine (predict) the failure of the machine component in the near future so that the component can be replaced programmatically based on the maintenance plane before it fails and stop the production process. In order to handle such a situation can improve the production process and increase productivity. With successfully handling with predictive maintenance we are able to achieve the following goals:\n",
    "\n",
    "- reduce the operational risk of mission-critical equipment\n",
    "- control cost of maintenance by enabling just-in-time maintenance operations\n",
    "- discover patterns connected to various maintenance problems\n",
    "- provide Key Performance Indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image shows diferent type of maintenance in the production.\n",
    "\n",
    "![predictive maintenance diagram](img/predictive_maintenance01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive maintenance data collection\n",
    "\n",
    "In order to handle and use this tecnique we we need a various data from the production, including but not limited to:\n",
    "- telemetry data from the observed machines (vibration, voltage, temperature etc)\n",
    "- errors and logs data relevant to each machine,\n",
    "- failure data, when a certain component is replaced, etc\n",
    "- quiality and accuracy data, machine properties, models, age etc.\n",
    "\n",
    "\n",
    "### 3 Steps in Predictive Maintenance\n",
    "\n",
    "Usually, every Predictive Maintenance technique should proceed by the following 3 main steps:\n",
    "1. **Collect Data**  - collect all possible descriptions, historical and real-time data, usually by using IOT devices, various loggers, technical documentation, etc.\n",
    "2. **Predict Failures** - collected data can be used and transformed into machine learning ready data sets, and build a machine learning model to predict the failures of the components in the set of machines in the production.\n",
    "3. **React** - by obtaining the information which components will fail in the near future, we can activate the process of replacement so the component will be replaced before it fails, and the proidcution process will not be interrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Failures\n",
    "\n",
    "In this article, the second step will be presented, which will be related to data preparation.  In order to predict failures in the production process, a set of data transformations, cleaning, feature engineering, and selection must be performed to prepare the data for building a machine learning model.\n",
    "The data preparation part plays a crucially step in the model building since a quality data preparation will directly reflect on the model accuracy and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software requirements \n",
    "\n",
    "In this article, the complete procedure in data preparation is presented. The whole process is performed using:\n",
    "\n",
    "- `.NET Jupyter Notebook`- .NET implementation of popular Jupyer Notebook, \n",
    "- `ML.NET` - Microsoft open-source framework for Machine Learning on .NET Platform and \n",
    "- `Daany` - **DA**ta **AN**al**Y**tics library with the implementation of DataFrame, Time series decomposition and various statistical parameters. It can be found at Github, it is distributed as a Nuget package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Step 1. Notebook preparation\n",
    "\n",
    "In order to complete this task, we shoudl install several Nuget packages, and inlcude several using keywords.\n",
    "The following code block shows the using stateent, as some data related to notebook formatting when the data is shown. \n",
    "\n",
    "\n",
    "\n",
    "**Note:** *nuget package installation must be in the first cell of the Notebook, otherwize the notebook will not work as expected. Hope this will change once the final version is released.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "//using Microsoft.ML.Data;\n",
    "using XPlot.Plotly;\n",
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using System.Drawing;\n",
    "using System.Linq;\n",
    "\n",
    "//using statement of Daany package\n",
    "using Daany;\n",
    "using Daany.MathStuff;\n",
    "using Daany.Ext;\n",
    "\n",
    "//\n",
    "using Microsoft.ML;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "//DataFrame formatter\n",
    "using Microsoft.AspNetCore.Html;\n",
    "Formatter<DataFrame>.Register((df, writer) =>\n",
    "{\n",
    "    var headers = new List<IHtmlContent>();\n",
    "    headers.Add(th(i(\"index\")));\n",
    "    headers.AddRange(df.Columns.Select(c => (IHtmlContent) th(c)));\n",
    "    \n",
    "    //renders the rows\n",
    "    var rows = new List<List<IHtmlContent>>();\n",
    "    var take = 20;\n",
    "    \n",
    "    //\n",
    "    for (var i = 0; i < Math.Min(take, df.RowCount()); i++)\n",
    "    {\n",
    "        var cells = new List<IHtmlContent>();\n",
    "        cells.Add(td(df.Index[i]));\n",
    "        foreach (var obj in df[i])\n",
    "        {\n",
    "            cells.Add(td(obj));\n",
    "        }\n",
    "        rows.Add(cells);\n",
    "    }\n",
    "    \n",
    "    var t = table(\n",
    "        thead(\n",
    "            headers),\n",
    "        tbody(\n",
    "            rows.Select(\n",
    "                r => tr(r))));\n",
    "    \n",
    "    writer.Write(t);\n",
    "}, \"text/html\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "In order to start with data preparation, we need data. The data can be found at Azure blob storage. The data is maintained by [Azure Gallery Article](https://gallery.azure.ai/Notebook/Predictive-Maintenance-Modelling-Guide-Python-Notebook-1). \n",
    "\n",
    "Once the data are downloaded from the blob storage, they will not be downloaded again, and they will be used local copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "//URL Paths for the data files used in the Notebook\n",
    "var urlTelemetry=\"https://azuremlsampleexperiments.blob.core.windows.net/datasets/PdM_telemetry.csv\";\n",
    "var urlErrors=\"https://azuremlsampleexperiments.blob.core.windows.net/datasets/PdM_errors.csv\";\n",
    "var urlMaintenance=\"https://azuremlsampleexperiments.blob.core.windows.net/datasets/PdM_maint.csv\";\n",
    "var urlFailures=\"https://azuremlsampleexperiments.blob.core.windows.net/datasets/PdM_failures.csv\";\n",
    "var urlMachines=\"https://azuremlsampleexperiments.blob.core.windows.net/datasets/PdM_machines.csv\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//check if the file exists\n",
    "if(!System.IO.File.Exists(\"data/PdM_telemetry.csv\"))\n",
    "{\n",
    "    using (System.Net.WebClient fileDownloader = new System.Net.WebClient())\n",
    "    {\n",
    "      fileDownloader.DownloadFile(urlTelemetry, \"data/PdM_telemetry.csv\");\n",
    "    }\n",
    "}\n",
    "else \n",
    "   display(\"Telemetry file exist\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//check if the file exists\n",
    "if(!System.IO.File.Exists(\"data/PdM_errors.csv\"))\n",
    "{\n",
    "    using (System.Net.WebClient fileDownloader = new System.Net.WebClient())\n",
    "    {\n",
    "      fileDownloader.DownloadFile(urlErrors, \"data/PdM_errors.csv\");\n",
    "    }\n",
    "}\n",
    "else \n",
    "    display(\"Error file exist\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//check if the file exists\n",
    "if(!System.IO.File.Exists(\"data/PdM_maint.csv\"))\n",
    "{\n",
    "    using (System.Net.WebClient fileDownloader = new System.Net.WebClient())\n",
    "    {\n",
    "      fileDownloader.DownloadFile(urlMaintenance, \"data/PdM_maint.csv\");\n",
    "    }\n",
    "}\n",
    "else \n",
    "    display(\"PdM_maint file exist\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//check if the file exists\n",
    "if(!System.IO.File.Exists(\"data/PdM_failures.csv\"))\n",
    "{\n",
    "    using (System.Net.WebClient fileDownloader = new System.Net.WebClient())\n",
    "    {\n",
    "      fileDownloader.DownloadFile(urlFailures, \"data/PdM_failures.csv\");\n",
    "    }\n",
    "}\n",
    "else \n",
    "    display(\"PdM_failures file exist\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "//check if the file exists\n",
    "if(!System.IO.File.Exists(\"data/PdM_machines.csv\"))\n",
    "{\n",
    "    using (System.Net.WebClient fileDownloader = new System.Net.WebClient())\n",
    "    {\n",
    "      fileDownloader.DownloadFile(urlMachines, \"data/PdM_machines.csv\");\n",
    "    }\n",
    "}\n",
    "else \n",
    "    display(\"urlMachines file exist\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have files on the local disk, we can load them into application memory and create `Danny` `DataFrame` objects.\n",
    "\n",
    "### The Data\n",
    "\n",
    "The data we are using for predictive maintenance can be classified to:\n",
    "- telemetry - which collects historical data about machine behavior (voltage, vibration, etc)\n",
    "- errors - the data about warnings and errors in the machines\n",
    "- maint - data about replacement and maintenance for the machines,\n",
    "- machines - descriptive information about the machines,\n",
    "- failures - data when a certain machine is stopped, due to component failure.\n",
    "\n",
    "We load all the files in order to fully prepare data for the training process. The following code sample, loads the data in to application memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "//Load ALL 5 data frame files\n",
    "//DataFrame Cols: datetime,machineID,volt,rotate,pressure,vibration\n",
    "var telemetry = DataFrame.FromCsv(\"data/PdM_telemetry.csv\", dformat: \"yyyy-mm-dd hh:mm:ss\");\n",
    "var errors = DataFrame.FromCsv(\"data/PdM_errors.csv\", dformat: \"yyyy-mm-dd hh:mm:ss\");\n",
    "var maint = DataFrame.FromCsv(\"data/PdM_maint.csv\", dformat: \"yyyy-mm-dd hh:mm:ss\");\n",
    "var failures = DataFrame.FromCsv(\"data/PdM_failures.csv\", dformat: \"yyyy-mm-dd hh:mm:ss\");\n",
    "var machines = DataFrame.FromCsv(\"data/PdM_machines.csv\", dformat: \"yyyy-mm-dd hh:mm:ss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "display($\"DataFrame: {nameof(telemetry)} size is ({telemetry.RowCount()},{telemetry.ColCount()})\");\n",
    "display($\"DataFrame: {nameof(errors)} size is ({errors.RowCount()},{errors.ColCount()})\");\n",
    "display($\"DataFrame: {nameof(maint)} size is ({maint.RowCount()},{maint.ColCount()})\");\n",
    "display($\"DataFrame: {nameof(failures)} size is ({failures.RowCount()},{failures.ColCount()})\");\n",
    "display($\"DataFrame: {nameof(machines)} size is ({machines.RowCount()},{machines.ColCount()})\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the main telemetry data contains nearl 900 000 rows, which is enought to trin a ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemetry\n",
    "\n",
    "The first data source is the telemetry data about machines. It consists of `voltage`, `rotation`, `pressure`, and `vibration` measurements measured from 100 machines in real-time hourly. The time period the data has been collected is during the year 2015. \n",
    "The following data shows the first 10 records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.Head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of the whole dataset is shown on the next cell. As can be seen, we have nearly million records for the machines, which is good starting point for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.Describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to see the visualization of the telemetry data, we can select on of several column and show it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//define filters columns (two dates columns)\n",
    "string[] cols = new string[] { \"datetime\", \"datetime\", \"machineID\" };\n",
    "\n",
    "//filter values for each column\n",
    "var valls = new List<object>();\n",
    "valls.Add(new DateTime(2015, 1, 1)); valls.Add(new DateTime(2015, 2, 1)); valls.Add(1);\n",
    "\n",
    "//now filter operator \n",
    "FilterOperator[] oprs = new FilterOperator[] { FilterOperator.Greather, FilterOperator.LessOrEqual, FilterOperator.Equal };\n",
    "\n",
    "//perform filtering \n",
    "var machine1Df = telemetry.Filter(cols, valls.ToArray(), oprs);\n",
    "\n",
    "//plot coordinates\n",
    "var x = machine1Df[\"datetime\"].Select(t => Convert.ToDateTime(t)).ToArray();\n",
    "var voltage1 = machine1Df[\"volt\"].Select(t => Convert.ToDouble(t)).ToArray();\n",
    "\n",
    "//Plot Telemetry data\n",
    "var chart = Chart.Plot(\n",
    "    new Graph.Scattergl()\n",
    "    {\n",
    "        x = x,\n",
    "        y = voltage1,\n",
    "      //  mode = \"markers\",  \n",
    "    }\n",
    "    \n",
    ");\n",
    "//\n",
    "var layout = new XPlot.Plotly.Layout.Layout() \n",
    "    { title = \"Machine Voltage\",\n",
    "     xaxis=new XPlot.Plotly.Graph.Xaxis() { title=\"Time\" }, \n",
    "     yaxis = new XPlot.Plotly.Graph.Yaxis() { title = \"Voltage\" } };\n",
    "//put layout into chart\n",
    "chart.WithLayout(layout);\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors\n",
    "One of the most important information in every Predictive Maintenance system is Error data. Actually errors are non-breaking recorded events while the machine is still operational. The error date and times are rounded to the closest hour since the telemetry data is collected at an hourly rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//count number of errors \n",
    "var barValue = errors[\"errorID\"].GroupBy(v => v)\n",
    "        .OrderBy(group => group.Key)\n",
    "        .Select(group => Tuple.Create(group.Key, group.Count()));\n",
    "\n",
    "//Plot Errors data\n",
    "var chart = Chart.Plot(\n",
    "    new Graph.Bar()\n",
    "    {\n",
    "       x = barValue.Select(x=>x.Item1),\n",
    "       y = barValue.Select(x=>x.Item2),\n",
    "      //  mode = \"markers\",  \n",
    "    }\n",
    "    \n",
    ");\n",
    "var layout = new XPlot.Plotly.Layout.Layout() \n",
    "    { title = \"Error distribution\",\n",
    "     xaxis=new XPlot.Plotly.Graph.Xaxis() { title=\"Error name\" }, \n",
    "     yaxis = new XPlot.Plotly.Graph.Yaxis() { title = \"Error Count\" } };\n",
    "//put layout into chart\n",
    "chart.WithLayout(layout);\n",
    "\n",
    "display(chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintenance\n",
    "\n",
    "The Maintenance is the next PrM component which tells us about scheduled and unscheduled maintenance. The maintenance contains the records which correspond to both regular inspection of components as well as failures. To add the record into the maintenance table a component must be replaced during the scheduled inspection or replaced due to a breakdown. In case the records are created due to breakdowns are called `failures`. Maintenance contains the data from 2014 and 2015 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "maint.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//count number of errors \n",
    "var barValue = maint[\"comp\"].GroupBy(v => v)\n",
    "        .OrderBy(group => group.Key)\n",
    "        .Select(group => Tuple.Create(group.Key, group.Count()));\n",
    "\n",
    "//Plot Errors data\n",
    "var chart = Chart.Plot(\n",
    "    new Graph.Bar()\n",
    "    {\n",
    "       x = barValue.Select(x=>x.Item1),\n",
    "       y = barValue.Select(x=>x.Item2),\n",
    "      //  mode = \"markers\",  \n",
    "    }\n",
    "    \n",
    ");\n",
    "var layout = new XPlot.Plotly.Layout.Layout() \n",
    "    { title = \"Components Replacements\",\n",
    "     xaxis=new XPlot.Plotly.Graph.Xaxis() { title=\"Component Name\" }, \n",
    "     yaxis = new XPlot.Plotly.Graph.Yaxis() { title = \"Number of components replaced\" } };\n",
    "//put layout into chart\n",
    "chart.WithLayout(layout);\n",
    "\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machines\n",
    "\n",
    "The data include information about 100 machines which are subject of the Predictive Maintenance analysis. The information includes: `model type`, and machine `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "machines.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//count number of errors \n",
    "var barValue = machines[\"age\"].GroupBy(v => v)\n",
    "        .OrderBy(group => group.Key)\n",
    "        .Select(group => Tuple.Create(group.Key, group.Count()));\n",
    "\n",
    "//Plot machine data\n",
    "var chart = Chart.Plot(\n",
    "    new Graph.Bar()\n",
    "    {\n",
    "       x = barValue.Select(x=>x.Item1),\n",
    "       y = barValue.Select(x=>x.Item2),\n",
    "       name = \"model1\",  \n",
    "    }\n",
    "    \n",
    ");\n",
    "var layout = new XPlot.Plotly.Layout.Layout() \n",
    "    { title = \"Components Replacements\",\n",
    "     xaxis=new XPlot.Plotly.Graph.Xaxis() { title=\"Machine Age\" }, \n",
    "     yaxis = new XPlot.Plotly.Graph.Yaxis() { title = \"Count\" } };\n",
    "//put layout into chart\n",
    "chart.WithLayout(layout);\n",
    "\n",
    "display(chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Distribution of models across age\n",
    "var d1 = machines.Filter(\"model\", \"model1\", FilterOperator.Equal)[\"age\"]\n",
    "                                    .GroupBy(g => g).Select(g=>(g.Key,g.Count()));\n",
    "var d2 = machines.Filter(\"model\", \"model2\", FilterOperator.Equal)[\"age\"]\n",
    "                                    .GroupBy(g => g).Select(g=>(g.Key,g.Count()));\n",
    "var d3 = machines.Filter(\"model\", \"model3\", FilterOperator.Equal)[\"age\"]\n",
    "                                    .GroupBy(g => g).Select(g=>(g.Key,g.Count()));\n",
    "var d4 = machines.Filter(\"model\", \"model4\", FilterOperator.Equal)[\"age\"]\n",
    "                                    .GroupBy(g => g).Select(g=>(g.Key,g.Count()));\n",
    "//define bars\n",
    "var b1 = new Graph.Bar(){ x = d1.Select(x=>x.Item1),y = d1.Select(x=>x.Item2),name = \"model1\"};\n",
    "var b2 = new Graph.Bar(){ x = d2.Select(x=>x.Item1),y = d2.Select(x=>x.Item2),name = \"model2\"};\n",
    "var b3 = new Graph.Bar(){ x = d3.Select(x=>x.Item1),y = d3.Select(x=>x.Item2),name = \"model3\"};\n",
    "var b4 = new Graph.Bar(){ x = d4.Select(x=>x.Item1),y = d4.Select(x=>x.Item2),name = \"model4\"};\n",
    "    \n",
    "    \n",
    "//Plot machine data\n",
    "var chart = Chart.Plot(new[] {b1,b2,b3,b4});\n",
    "\n",
    "var layout = new XPlot.Plotly.Layout.Layout() \n",
    "    { title = \"Components Replacements\",barmode=\"stack\",\n",
    "     xaxis=new XPlot.Plotly.Graph.Xaxis() { title=\"Machine Age\" }, \n",
    "     yaxis = new XPlot.Plotly.Graph.Yaxis() { title = \"Count\" } };\n",
    "//put layout into chart\n",
    "chart.WithLayout(layout);\n",
    "\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failures\n",
    "\n",
    "The Failures represent the replacements of the components due to the failure of the machines. Once the failure is happend the machine is stopped. This is a crucial difference between Errors and Failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//count number of failures  \n",
    "var falValues = failures[\"failure\"].GroupBy(v => v)\n",
    "        .OrderBy(group => group.Key)\n",
    "        .Select(group => Tuple.Create(group.Key, group.Count()));\n",
    "\n",
    "//Plot Failure data\n",
    "var chart = Chart.Plot(\n",
    "    new Graph.Bar()\n",
    "    {\n",
    "       x = falValues.Select(x=>x.Item1),\n",
    "       y = falValues.Select(x=>x.Item2),\n",
    "      //  mode = \"markers\",  \n",
    "    }\n",
    "    \n",
    ");\n",
    "var layout = new XPlot.Plotly.Layout.Layout() \n",
    "    { title = \"Failure Distribution acorss machines\",\n",
    "     xaxis=new XPlot.Plotly.Graph.Xaxis() { title=\"Component Name\" }, \n",
    "     yaxis = new XPlot.Plotly.Graph.Yaxis() { title = \"Number of components replaces\" } };\n",
    "//put layout into chart\n",
    "chart.WithLayout(layout);\n",
    "\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section contains several feature engineering methods used to create features based on the machines' properties.\n",
    "\n",
    "### Lagged Telemetry Features\n",
    "\n",
    "First, we are going to create several lagged telemetry data, since telemetry data are classic time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the rolling mean and standard deviation of the telemetry data over the last 3-hour lag window is calculated for every 3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//prepare rolling aggregation for each column for average values\n",
    "var agg_curent = new Dictionary<string, Aggregation>()\n",
    " {\n",
    "    { \"datetime\", Aggregation.Last }, { \"volt\", Aggregation.Last }, { \"rotate\", Aggregation.Last },\n",
    "    { \"pressure\", Aggregation.Last },{ \"vibration\", Aggregation.Last }\n",
    "  };\n",
    "//prepare rolling aggregation for each column for average values\n",
    "var agg_mean = new Dictionary<string, Aggregation>()\n",
    " {\n",
    "    { \"datetime\", Aggregation.Last }, { \"volt\", Aggregation.Avg }, { \"rotate\", Aggregation.Avg },\n",
    "    { \"pressure\", Aggregation.Avg },{ \"vibration\", Aggregation.Avg }\n",
    "  };\n",
    "//prepare rolling aggregation for each column for std values\n",
    "var agg_std = new Dictionary<string, Aggregation>()\n",
    "{\n",
    "   { \"datetime\", Aggregation.Last }, { \"volt\", Aggregation.Std }, { \"rotate\", Aggregation.Std },\n",
    "    { \"pressure\", Aggregation.Std },{ \"vibration\", Aggregation.Std }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//group Telemetry data by machine ID\n",
    "var groupedTelemetry = telemetry.GroupBy(\"machineID\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//calculate rolling mean for grouped data for each 3 hours\n",
    "var _3AvgValue = groupedTelemetry.Rolling(3, 3, agg_mean)\n",
    "                 .Create((\"machineID\", null), (\"datetime\", null),(\"volt\", \"voltmean_3hrs\"), (\"rotate\", \"rotatemean_3hrs\"),\n",
    "                         (\"pressure\", \"pressuremean_3hrs\"), (\"vibration\", \"vibrationmean_3hrs\"));\n",
    "//show head of the newely generated table\n",
    "_3AvgValue.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3AvgValue.Tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//calculate rolling std for grouped datat fro each 3 hours\n",
    "var _3StdValue = groupedTelemetry.Rolling(3, 3, agg_mean)\n",
    "                 .Create((\"machineID\", null), (\"datetime\", null),(\"volt\", \"voltsd_3hrs\"), (\"rotate\", \"rotatesd_3hrs\"),\n",
    "                         (\"pressure\", \"pressuresd_3hrs\"), (\"vibration\", \"vibrationsd_3hrs\"));\n",
    "//show head of the newely generated table\n",
    "_3StdValue.Head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For caputing a longer term effect 24 hours lag features we are going to calculate rolling avf and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//calculate rolling avg and std for each 24 hours\n",
    "var _24AvgValue = groupedTelemetry.Rolling(24, 3, agg_mean)\n",
    "                .Create((\"machineID\", null), (\"datetime\", null),\n",
    "                        (\"volt\", \"voltmean_24hrs\"), (\"rotate\", \"rotatemean_24hrs\"),\n",
    "                        (\"pressure\", \"pressuremean_24hrs\"), (\"vibration\", \"vibrationmean_24hrs\"));\n",
    "var _24StdValue = groupedTelemetry.Rolling(24, 3, agg_std)\n",
    "                .Create((\"machineID\", null), (\"datetime\", null),\n",
    "                        (\"volt\", \"voltsd_24hrs\"), (\"rotate\", \"rotatesd_24hrs\"),\n",
    "                        (\"pressure\", \"pressuresd_24hrs\"), (\"vibration\", \"vibrationsd_24hrs\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging telemetry features\n",
    "\n",
    "Once we have rolling lag features calculated, we can merge them into one data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//before merge all features create set of features from the current values for every 3 or 24 hours\n",
    "DataFrame _1CurrentValue = groupedTelemetry.Rolling(3, 3, agg_curent)\n",
    "                            .Create((\"machineID\", null), (\"datetime\", null),\n",
    "                            (\"volt\", null), (\"rotate\", null), (\"pressure\", null), (\"vibration\", null));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//merge all telemetry data frames into one\n",
    "var mergeCols= new string[] { \"machineID\", \"datetime\" };\n",
    "var df1 = _1CurrentValue.Merge(_3AvgValue, mergeCols, mergeCols, JoinType.Left, suffix: \"df1\");   \n",
    "                                            \n",
    "var df2 = df1.Merge(_24AvgValue, mergeCols, mergeCols, JoinType.Left, suffix: \"df2\");\n",
    "                                 \n",
    "var df3 = df2.Merge(_3StdValue, mergeCols, mergeCols, JoinType.Left, suffix: \"df3\");\n",
    "                                \n",
    "var df4 = df3.Merge(_24StdValue, mergeCols, mergeCols, JoinType.Left, suffix: \"df4\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//select final dataset for the telemetry\n",
    "var telDF = df4[\"machineID\",\"datetime\",\"volt\",\"rotate\", \"pressure\", \"vibration\",\n",
    "                 \"voltmean_3hrs\",\"rotatemean_3hrs\",\"pressuremean_3hrs\",\"vibrationmean_3hrs\",\n",
    "                 \"voltmean_24hrs\",\"rotatemean_24hrs\",\"pressuremean_24hrs\",\"vibrationmean_24hrs\",\n",
    "                 \"voltsd_3hrs\", \"rotatesd_3hrs\",\"pressuresd_3hrs\",\"vibrationsd_3hrs\",\n",
    "                 \"voltsd_24hrs\", \"rotatesd_24hrs\",\"pressuresd_24hrs\",\"vibrationsd_24hrs\"];\n",
    "\n",
    "//remove NANs\n",
    "var telemetry_final = telDF.DropNA();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_final.Head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Features from Errors\n",
    "\n",
    "Unlike telemetry that had numerical values, errors have categorical values denoting the type of error that occurred at a time-stamp. We are going to aggregate categories of the error with different types of errors that occurred in the lag window.\n",
    "\n",
    "First, encode the errors with One-Hot-Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "var mlContext = new MLContext(seed:2019);\n",
    "//One Hot Encoding of error column\n",
    "var encodedErr = errors.EncodeColumn(mlContext, \"errorID\");\n",
    "\n",
    "//sum duplicated erros by machine and date\n",
    "var errors_aggs = new Dictionary<string, Aggregation>();\n",
    "errors_aggs.Add(\"error1\", Aggregation.Sum);\n",
    "errors_aggs.Add(\"error2\", Aggregation.Sum);\n",
    "errors_aggs.Add(\"error3\", Aggregation.Sum);\n",
    "errors_aggs.Add(\"error4\", Aggregation.Sum);\n",
    "errors_aggs.Add(\"error5\", Aggregation.Sum);\n",
    "\n",
    "//group and sum duplicated errors\n",
    "encodedErr =  encodedErr.GroupBy(new string[] { \"machineID\", \"datetime\" }).Aggregate(errors_aggs);\n",
    "\n",
    "//\n",
    "encodedErr = encodedErr.Create((\"machineID\", null), (\"datetime\", null),\n",
    "                        (\"error1\", \"error1sum\"), (\"error2\", \"error2sum\"),\n",
    "                        (\"error3\", \"error3sum\"), (\"error4\", \"error4sum\"), (\"error5\", \"error5sum\"));\n",
    "encodedErr.Head()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "// align errors with telemetry datetime values so that we can calculate aggregations\n",
    "var er = telemetry.Merge(encodedErr,mergeCols, mergeCols, JoinType.Left, suffix: \"error\");\n",
    "//\n",
    "er = er[\"machineID\",\"datetime\", \"error1sum\", \"error2sum\", \"error3sum\", \"error4sum\", \"error5sum\"];\n",
    "//fill missing values with 0\n",
    "er.FillNA(0);\n",
    "er.Head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//count the number of errors of different types in the last 24 hours, for every 3 hours\n",
    "//define aggregation\n",
    "var errors_aggs1 = new Dictionary<string, Aggregation>()\n",
    "{\n",
    "  { \"datetime\", Aggregation.Last },{ \"error1sum\", Aggregation.Sum }, { \"error2sum\", Aggregation.Sum }, \n",
    "  { \"error3sum\", Aggregation.Sum },{ \"error4sum\", Aggregation.Sum },\n",
    "  { \"error5sum\", Aggregation.Sum }\n",
    "};\n",
    "\n",
    "//count the number of errors of different types in the last 24 hours,  for every 3 hours\n",
    "var eDF = er.GroupBy(new string[] { \"machineID\"}).Rolling(24, 3, errors_aggs1);\n",
    "\n",
    "//\n",
    "var newdf=  eDF.DropNA();\n",
    "\n",
    "var errors_final = newdf.Create((\"machineID\", null), (\"datetime\", null),\n",
    "                        (\"error1sum\", \"error1count\"), (\"error2sum\", \"error2count\"),\n",
    "                        (\"error3sum\", \"error3count\"), (\"error4sum\", \"error4count\"), (\"error5sum\", \"error5count\"));\n",
    "errors_final.Head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Since Last Replacement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the main task here is how to create a relevant feature in order to create a quality data set for the machine learning part. One of the good features would be the number of replacements of each component in the last 3 months to incorporate the frequency of replacements. \n",
    "\n",
    "Furthermore, we can calculate how long it has been since a component is last replaced as that would be expected to correlate better with component failures since the longer a component is used, the more degradation should be expected.\n",
    " As first we are going to encode the maintenance table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//One Hot Encoding of error column\n",
    "var encMaint = maint.EncodeColumn(mlContext, \"comp\");\n",
    "encMaint.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//create separate data frames in order to calculate proper time since last replacement \n",
    "DataFrame dfComp1 = encMaint.Filter(\"comp1\", 1, FilterOperator.Equal)[\"machineID\", \"datetime\"];\n",
    "DataFrame dfComp2 = encMaint.Filter(\"comp2\", 1, FilterOperator.Equal)[\"machineID\", \"datetime\"];;\n",
    "DataFrame dfComp3 = encMaint.Filter(\"comp3\", 1, FilterOperator.Equal)[\"machineID\", \"datetime\"];;\n",
    "DataFrame dfComp4 = encMaint.Filter(\"comp4\", 1, FilterOperator.Equal)[\"machineID\", \"datetime\"];;\n",
    "\n",
    "dfComp4.Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//from telemetry data create helped dataframe so we can calculate additional column from the maintenance data frame\n",
    "var compData = telemetry_final.Create((\"machineID\", null), (\"datetime\", null));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "//calculate new set of columns so that we have information the time since last replacement of each component separetly\n",
    "var newCols= new string[]{\"sincelastcomp1\",\"sincelastcomp2\",\"sincelastcomp3\",\"sincelastcomp4\"};\n",
    "var calcValues= new object[4];\n",
    "\n",
    "//perform calculation\n",
    "compData.AddCalculatedColumns(newCols,(row, i)=>\n",
    "{\n",
    "    var machineId = Convert.ToInt32(row[\"machineID\"]);\n",
    "    var date = Convert.ToDateTime(row[\"datetime\"]);\n",
    "    \n",
    "    var maxDate1 = dfComp1.Filter(\"machineID\", machineId, FilterOperator.Equal)[\"datetime\"]\n",
    "        .Where(x => (DateTime)x <= date).Select(x=>(DateTime)x).Max();\n",
    "    var maxDate2 = dfComp2.Filter(\"machineID\", machineId, FilterOperator.Equal)[\"datetime\"]\n",
    "        .Where(x => (DateTime)x <= date).Select(x=>(DateTime)x).Max();\n",
    "    var maxDate3 = dfComp3.Filter(\"machineID\", machineId, FilterOperator.Equal)[\"datetime\"]\n",
    "        .Where(x => (DateTime)x <= date).Select(x=>(DateTime)x).Max();\n",
    "    var maxDate4 = dfComp4.Filter(\"machineID\", machineId, FilterOperator.Equal)[\"datetime\"]\n",
    "        .Where(x => (DateTime)x <= date).Select(x=>(DateTime)x).Max();\n",
    "        \n",
    "    //perform calculation\n",
    "    calcValues[0] = (date - maxDate1).TotalDays;\n",
    "    calcValues[1] = (date - maxDate2).TotalDays;\n",
    "    calcValues[2] = (date - maxDate3).TotalDays;\n",
    "    calcValues[3] = (date - maxDate4).TotalDays;\n",
    "    return calcValues;\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "var maintenance_final = compData;\n",
    "maintenance_final.Head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Features\n",
    "\n",
    "The machine data set contains descriptive information about machines like the type of machines and their ages which is the years in service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "machines.Head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining features into final ML ready data set\n",
    "\n",
    "As the last step in Feature engineering, we are performing merging all features into one data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "var merge2Cols=new string[]{\"machineID\"};\n",
    "var fdf1= telemetry_final.Merge(errors_final, mergeCols, mergeCols,JoinType.Left, suffix: \"er\");\n",
    "var fdf2 = fdf1.Merge(maintenance_final, mergeCols,mergeCols,JoinType.Left, suffix: \"mn\");\n",
    "var features_final = fdf2.Merge(machines, merge2Cols,merge2Cols,JoinType.Left, suffix: \"ma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final= features_final[\"datetime\", \"machineID\", \n",
    "            \"voltmean_3hrs\", \"rotatemean_3hrs\", \"pressuremean_3hrs\", \"vibrationmean_3hrs\",\n",
    "            \"voltsd_3hrs\", \"rotatesd_3hrs\", \"pressuresd_3hrs\", \"vibrationsd_3hrs\", \n",
    "            \"voltmean_24hrs\", \"rotatemean_24hrs\", \"pressuremean_24hrs\", \"vibrationmean_24hrs\", \n",
    "            \"voltsd_24hrs\",\"rotatesd_24hrs\", \"pressuresd_24hrs\", \"vibrationsd_24hrs\", \n",
    "            \"error1count\", \"error2count\", \"error3count\", \"error4count\", \"error5count\", \n",
    "            \"sincelastcomp1\", \"sincelastcomp2\", \"sincelastcomp3\", \"sincelastcomp4\", \n",
    "            \"model\", \"age\"];\n",
    "//\n",
    "\n",
    "features_final.Head();\n",
    "DataFrame.ToCsv(\"data/final_features.csv\", features_final);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Label Column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Label in prediction maintenance should be the probability that a machine will fail in the near future due to a failure certain component. If we take 24 hours to be a task for this problem, the label construction is consists of a new column in the feature data set which indicate if certain machine will fail or not in the next 24 hours due to failure one of several components. \n",
    "\n",
    "With this way we are defining the label as a categorical variable containing:\n",
    "- `none` - if the machine will not fail in the next 24 hours,\n",
    "- `comp1` to `comp4` - if the machine will fail in the next 24 hours due to the failure of cetain components.\n",
    "\n",
    "Since we can experiment with the label construction by applying different conditions, we can implement methods that take several arguments in order to define the general problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures.Describe(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//constructing the label column which indicate if the current machine will \n",
    "//fail in the next `predTime` (24 hours as default) due to failur certain component.\n",
    "//create final data frame from from feature df\n",
    "var finalDf = new DataFrame(features_final);\n",
    "\n",
    "//group failures by machineID and datetime \n",
    "string[] cols = new string[] {  \"machineID\" , \"datetime\"};\n",
    "var failDfgrp = failures.GroupBy(cols);\n",
    "\n",
    "//Add failure column to  finalDF\n",
    "var rV = new object[] { \"none\" };\n",
    "finalDf.AddCalculatedColumns(new string[]{\"failure\"}, (object[] row, int i) => rV);\n",
    "\n",
    "//create new data frame from featuresDF by grouping machineID and datatime\n",
    "var featureDfGrouped = finalDf[\"datetime\",\"machineID\", \"failure\"].GroupBy(cols);\n",
    "\n",
    "//now look for every failure and calculate if the machine will fail in the last 24 hours\n",
    "//in case two or more components were failed for the ssame machine add new row in df\n",
    "var failureDfExt = featureDfGrouped.Transform((xdf) =>\n",
    "{\n",
    "    //extract the row from featureDfGrouped\n",
    "    var xdfRow = xdf[0].ToList();\n",
    "    var refDate = (DateTime)xdfRow[0];\n",
    "    var machineID = (int)xdfRow[1];\n",
    "\n",
    "    //now look if the failure contains the machineID\n",
    "    if(failDfgrp.Group2.ContainsKey(machineID))\n",
    "    {\n",
    "        //get the date and calculate total hours\n",
    "        var dff = failDfgrp.Group2[machineID];\n",
    "\n",
    "        foreach (var dfff in dff)\n",
    "        {\n",
    "            for (int i = 0; i < dfff.Value.RowCount(); i++)\n",
    "            {\n",
    "                //\"datetime\",\"machineID\",\"failure\"\n",
    "                var frow = dfff.Value[i].ToList();\n",
    "                var dft = (DateTime)frow[0];\n",
    "                \n",
    "                //if total hours is less or equal than 24 hours set component to the failure column\n",
    "                var totHours = (dft - refDate).TotalHours;\n",
    "                if (totHours <= 24 && totHours >=0)\n",
    "                {\n",
    "                    if (xdf.RowCount() > i)\n",
    "                        xdf[\"failure\", i] = frow[2];\n",
    "                    else//in case two components were failed for the same machine and \n",
    "                        //at the same time, add new row with new component name\n",
    "                    {\n",
    "                        var r = xdf[0].ToList();\n",
    "                        r[2] = frow[2];\n",
    "                        xdf.AddRow(r);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return xdf;\n",
    "});\n",
    "\n",
    "//Now merge extended failure Df with featureDF\n",
    "var final_dataframe = finalDf.Merge(failureDfExt, cols, cols,JoinType.Left, \"fail\");\n",
    "\n",
    "//define final set of columns\n",
    "final_dataframe = final_dataframe[\"datetime\", \"machineID\",\n",
    "\"voltmean_3hrs\", \"rotatemean_3hrs\", \"pressuremean_3hrs\", \"vibrationmean_3hrs\",\n",
    "\"voltsd_3hrs\", \"rotatesd_3hrs\", \"pressuresd_3hrs\", \"vibrationsd_3hrs\",\n",
    "\"voltmean_24hrs\", \"rotatemean_24hrs\", \"pressuremean_24hrs\", \"vibrationmean_24hrs\",\n",
    "\"voltsd_24hrs\", \"rotatesd_24hrs\", \"pressuresd_24hrs\", \"vibrationsd_24hrs\",\n",
    "\"error1count\", \"error2count\", \"error3count\", \"error4count\", \"error5count\",\n",
    "\"sincelastcomp1\", \"sincelastcomp2\", \"sincelastcomp3\", \"sincelastcomp4\",\n",
    "\"model\", \"age\", \"failure_fail\"];\n",
    "\n",
    "//rename column\n",
    "final_dataframe.Rename((\"failure_fail\", \"failure\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "//save the file data frame to disk\n",
    "DataFrame.ToCsv(\"data/final_dataFrame.csv\",final_dataframe);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data Frame \n",
    "\n",
    "Lets see how looks like our final data frame. The final data frame contains 24 columns. Most of the columns are numerical. The `Model` column is categorical and it should be encoded once we prepare the macihne leraning part.\n",
    "\n",
    "Also the lable column `failure` is categorical column containing 5 diferent categories: `none`, `comp1`, `comp2`, `comp3` and `comp4`. We can also see the data set is not balance, since we have `2785705` `none` and the rest of the rows in total of 5923 other categories. This is typical unbalanced dataset, and we should be carefull when evaluation models, because the mdoel which returns always `none` value will have more than 97% of accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.Describe(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we are going to implement the training and evaluation process of the Predictive Maintenance model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": ".net-csharp"
  },
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
